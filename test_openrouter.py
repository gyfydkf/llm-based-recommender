#!/usr/bin/env python3
"""
æµ‹è¯•OpenRouteré…ç½®çš„è„šæœ¬
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

def test_env_variables():
    """æµ‹è¯•ç¯å¢ƒå˜é‡æ˜¯å¦æ­£ç¡®åŠ è½½"""
    print("ğŸ” æ£€æŸ¥ç¯å¢ƒå˜é‡...")
    
    # æ£€æŸ¥å…³é”®ç¯å¢ƒå˜é‡
    env_vars = {
        "OPENAI_API_KEY": os.environ.get("OPENAI_API_KEY"),
        "OPENAI_API_BASE": os.environ.get("OPENAI_API_BASE"),
        "LLM_MODEL_NAME": os.environ.get("LLM_MODEL_NAME"),
        "KAGGLE_USERNAME": os.environ.get("KAGGLE_USERNAME"),
        "KAGGLE_KEY": os.environ.get("KAGGLE_KEY"),
    }
    
    for var_name, value in env_vars.items():
        if value:
            if "KEY" in var_name:
                print(f"   âœ… {var_name}: {'*' * min(len(str(value)), 20)}...")
            else:
                print(f"   âœ… {var_name}: {value}")
        else:
            print(f"   âŒ {var_name}: æœªè®¾ç½®")
    
    return all(env_vars.values())


def test_openrouter_connection():
    """æµ‹è¯•OpenRouterè¿æ¥"""
    print("\nğŸš€ æµ‹è¯•OpenRouterè¿æ¥...")
    
    try:
        from src.recommender.llm_factory import test_llm_connection
        
        if test_llm_connection("openrouter"):
            print("   âœ… OpenRouterè¿æ¥æˆåŠŸï¼")
            return True
        else:
            print("   âŒ OpenRouterè¿æ¥å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"   âŒ OpenRouterè¿æ¥é”™è¯¯: {e}")
        return False


def test_ollama_fallback():
    """æµ‹è¯•Ollamaå¤‡ç”¨è¿æ¥"""
    print("\nğŸ¦™ æµ‹è¯•Ollamaå¤‡ç”¨è¿æ¥...")
    
    try:
        from src.recommender.llm_factory import test_llm_connection
        
        if test_llm_connection("ollama"):
            print("   âœ… Ollamaè¿æ¥æˆåŠŸï¼")
            return True
        else:
            print("   âŒ Ollamaè¿æ¥å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"   âŒ Ollamaè¿æ¥é”™è¯¯: {e}")
        return False


def test_simple_llm_call():
    """æµ‹è¯•ç®€å•çš„LLMè°ƒç”¨"""
    print("\nğŸ’¬ æµ‹è¯•LLMè°ƒç”¨...")
    
    try:
        from src.recommender.llm_factory import get_llm
        
        llm = get_llm("auto")
        response = llm.invoke("Hello, can you help me with fashion recommendations?")
        
        print(f"   âœ… LLMå“åº”æˆåŠŸ: {response.content[:100]}...")
        return True
        
    except Exception as e:
        print(f"   âŒ LLMè°ƒç”¨é”™è¯¯: {e}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª OpenRouteré…ç½®æµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•ç¯å¢ƒå˜é‡
    env_ok = test_env_variables()
    
    if not env_ok:
        print("\nâš ï¸  ç¯å¢ƒå˜é‡é…ç½®ä¸å®Œæ•´ï¼Œè¯·æ£€æŸ¥.envæ–‡ä»¶")
        return
    
    # æµ‹è¯•OpenRouterè¿æ¥
    openrouter_ok = test_openrouter_connection()
    
    # æµ‹è¯•Ollamaå¤‡ç”¨
    ollama_ok = test_ollama_fallback()
    
    # æµ‹è¯•LLMè°ƒç”¨
    llm_ok = test_simple_llm_call()
    
    print("\n" + "=" * 50)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    print(f"   ç¯å¢ƒå˜é‡: {'âœ…' if env_ok else 'âŒ'}")
    print(f"   OpenRouter: {'âœ…' if openrouter_ok else 'âŒ'}")
    print(f"   Ollamaå¤‡ç”¨: {'âœ…' if ollama_ok else 'âŒ'}")
    print(f"   LLMè°ƒç”¨: {'âœ…' if llm_ok else 'âŒ'}")
    
    if openrouter_ok or ollama_ok:
        print("\nğŸ‰ é…ç½®æˆåŠŸï¼ä½ çš„LLMåº”è¯¥å¯ä»¥æ­£å¸¸å·¥ä½œäº†ã€‚")
    else:
        print("\nâŒ é…ç½®å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIå¯†é’¥ã€‚")


if __name__ == "__main__":
    main() 