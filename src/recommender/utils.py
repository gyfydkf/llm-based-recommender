"""
This module contains utility functions for the recommender service.
"""

import re
from langchain.prompts import PromptTemplate
from langchain_community.query_constructors.chroma import (
    ChromaTranslator as BaseChromaTranslator,
)
from langchain_core.structured_query import Comparator, Comparison
from loguru import logger
import json
import requests
import ast
import os
from src.config import settings


def detect_language(text: str) -> str:
    """
    Detect if the text contains Chinese characters.
    
    Args:
        text: Input text to analyze
        
    Returns:
        'zh' if Chinese characters are detected, 'en' otherwise
    """
    # Check for Chinese characters (Unicode range for Chinese)
    chinese_pattern = re.compile(r'[\u4e00-\u9fff]')
    if chinese_pattern.search(text):
        return 'zh'
    return 'en'


def get_language_specific_response(query: str, response_type: str = "error") -> str:
    """
    Get language-specific response based on the query language.
    
    Args:
        query: User query to detect language
        response_type: Type of response needed ('error', 'thinking', etc.)
        
    Returns:
        Language-specific response string
    """
    language = detect_language(query)
    
    responses = {
        'error': {
            'en': "I'm sorry, I can't help with that. Please ask a query related to product recommendations.",
            'zh': "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å¸®åŠ©æ‚¨è§£å†³è¿™ä¸ªé—®é¢˜ã€‚è¯·è¯¢é—®ä¸äº§å“æ¨èç›¸å…³çš„æŸ¥è¯¢ã€‚"
        },
        'thinking': {
            'en': "ğŸ¤– Thinking...",
            'zh': "ğŸ¤– æ­£åœ¨æ€è€ƒ..."
        },
        'no_recommendation': {
            'en': "No recommendation found for your request.",
            'zh': "æ²¡æœ‰æ‰¾åˆ°é€‚åˆæ‚¨éœ€æ±‚çš„æ¨èã€‚"
        }
    }
    
    return responses.get(response_type, {}).get(language, responses[response_type]['en'])


class CustomChromaTranslator(BaseChromaTranslator):
    def __init__(self):
        super().__init__()
        # `allowed_comparators` is a list; convert to set, then add `LIKE` and `CONTAIN`, then back to list
        if self.allowed_comparators is None:
            self.allowed_comparators = []
        allowed_comparator_set = set(self.allowed_comparators)
        allowed_comparator_set.add(Comparator.LIKE)
        allowed_comparator_set.add(Comparator.CONTAIN)
        self.allowed_comparators = list(allowed_comparator_set)

    def visit_comparison(self, comparison: Comparison):
        """
        Chroma does NOT support $regex or $contains operators.
        For size matching, we'll skip the filter since ChromaDB doesn't support substring matching.
        This will allow semantic search to work while avoiding the filtering error.
        """
        if comparison.comparator == Comparator.LIKE or comparison.comparator == Comparator.CONTAIN:
            # Skip size filtering for now since ChromaDB doesn't support substring matching
            # This will allow the query to proceed with semantic search only
            return None
        # Otherwise, do default logic for eq, gt, gte, lt, lte, etc.
        return super().visit_comparison(comparison)


ATTRIBUTE_INFO = [
    {
        "name": "Product Details",
        "description": "Details about the product",
    },
    {
        "name": "Brand Name",
        "description": "Name of the brand",
    },
    {
        "name": "Available Sizes",
        "description": (
            "Sizes available for the product (stored as a comma-separated string, e.g., 'small, medium, large'). "
            "Note: Size filtering is not supported in this implementation."
        ),
    },
    {
        "name": "Product Price",
        "description": "Price of the product. Use `lt`, `lte`, `gt`, or `gte` for filtering.",
    },
]

DOC_CONTENT = "A detailed description of an e-commerce product, including its features, benefits, and specifications."


def get_metadata_info():
    return ATTRIBUTE_INFO, DOC_CONTENT


def create_rag_template():
    prompt_template = """ä½ æ˜¯ä¸€ä¸ªæ—¶å°šç©¿æ­é¢†åŸŸçš„æ™ºèƒ½è´­ç‰©åŠ©æ‰‹ã€‚ä½ åˆšåˆšæ ¹æ®ç”¨æˆ·éœ€æ±‚æ‰¾åˆ°äº†ä¸€äº›å¯ç”¨çš„äº§å“ï¼Œæ­£åœ¨å‘ç”¨æˆ·ä»‹ç»è¿™äº›æœè£…äº§å“ã€‚

    ç”¨æˆ·æ­£åœ¨å¯»æ‰¾ä¸ä»¥ä¸‹å†…å®¹ç›¸å…³çš„äº§å“ï¼š**{query}**

    ä»¥ä¸‹æ˜¯ä¸€äº›å¯ç”¨çš„äº§å“ï¼š
    {docs}

    æ³¨æ„ï¼ï¼ï¼è¯·ä»¥å‹å¥½ã€å¯¹è¯å¼çš„è¯­æ°”æ¨èä»¥ä¸Šæ‰€æœ‰å¯ç”¨äº§å“ï¼Œä¸”è¿™äº›äº§å“çš„å‡ºç°é¡ºåºä¸å¾—æ”¹åŠ¨ã€‚

    è¯·è€ƒè™‘ä»¥ä¸‹å› ç´ ï¼š
    - **ä¸ç”¨æˆ·åå¥½çš„åŒ¹é…**ï¼ˆä¾‹å¦‚ï¼Œä»·æ ¼ã€å“ç‰Œã€é£æ ¼ç­‰ï¼‰
    - **é«˜ç”¨æˆ·è¯„åˆ†å’Œå—æ¬¢è¿ç¨‹åº¦**
    - **ä¸ç”¨æˆ·æ„å›¾çš„ç›¸å…³æ€§**

    **è¯·ç”¨è‡ªç„¶è¯­è¨€å›å¤ï¼Œå°±åƒä½ äº²è‡ªåœ¨å¸®åŠ©ç”¨æˆ·ä¸€æ ·ã€‚**
    
    ç¤ºä¾‹å›å¤ï¼ˆä»…ä¾›å‚è€ƒï¼‰ï¼š
    "æ ¹æ®æ‚¨çš„éœ€æ±‚ï¼Œä»¥ä¸‹æ˜¯ä¸€äº›å¾ˆæ£’çš„é€‰æ‹©ï¼š
    1. [äº§å“A] - è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é€‰æ‹©ï¼Œå› ä¸º...
    2. [äº§å“B] - è¿™ä¸ªäº§å“å¾ˆçªå‡ºï¼Œå› ä¸º...
    
    å¦‚æœæ‚¨éœ€è¦æ›´å¤šè¯¦ç»†ä¿¡æ¯æˆ–æ›¿ä»£æ–¹æ¡ˆï¼Œè¯·å‘Šè¯‰æˆ‘ï¼"
    """

    prompt = PromptTemplate(template=prompt_template, input_variables=["docs", "query"])
    return prompt

CATEGORY_KEYWORDS = ["é•¿è£™", "é•¿è£¤", "çŸ­è£™", "çŸ­è£¤", "è¡¬è¡«", "Tæ¤", "Poloè¡«", "ä¼‘é—²è£¤"]

def extract_category_from_query(query):
    for cat in CATEGORY_KEYWORDS:
        if cat in query:
            return cat
    return None

def extract_details_from_doc(doc):
    details = ""
    if hasattr(doc, "page_content"):
        # å°è¯•ä» page_content çš„ JSON ä¸­æå– Product Details
        try:
            content_dict = json.loads(doc.page_content)
            details = content_dict.get("Product Details", "")
        except (json.JSONDecodeError, AttributeError):
            # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹ page_content
            details = doc.page_content
    return details

def basic_filter(query, docs):
    filtered = []
    bottoms = ["è£¤", "è£™"]
    if "è¡£" in query and "è£¤" in query:
        filtered = docs
    elif "è¡£" in query:
        filtered = [doc for doc in docs if not any(bottom in extract_details_from_doc(doc) for bottom in bottoms)]
    elif "è£¤" in query:
        filtered = [doc for doc in docs if "è£¤" in extract_details_from_doc(doc)]
    elif "è£™" in query:
        filtered = [doc for doc in docs if "è£™" in extract_details_from_doc(doc)]
    return filtered

def filter_docs_by_category(docs, category):
    if not category:
        return docs
    filtered = []
    logger.info(f"Filtering docs by category: {category}")
    for doc in docs:
        details = extract_details_from_doc(doc)
        logger.info(f"Details: {details}")
        if category in details:
            filtered.append(doc)
    return filtered

def convert_item_to_page_content(item):
    page_content_dict = {
        "Brand Name": item["brand"],
        "Product Details": item["description"],
        "Product Price": item["price"],
        "Available Sizes": ", ".join([variation["sizeName"] for variation in item["variations"]]),
    }
    return json.dumps(page_content_dict, indent=2, ensure_ascii=False)


def get_product_details():
    base_url = "https://cloudawn3d.com/mall/getProductDetail/"
    out_path = settings.PROCESSED_DATA_PATH

    try:
        database = []
        logger.info(f"Fetching product details from database...")
        for i in range(1,13):
            response = requests.get(base_url + str(i))
            response.raise_for_status()  # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ
            response_text = json.loads(response.text)
            if "data" in response_text:
                database.append(response_text["data"])
        logger.info(f"loaded {len(database)} items")
        os.makedirs(os.path.dirname(out_path), exist_ok=True)
        with open(out_path, "w", encoding="utf-8") as f:
            json.dump(database, f, ensure_ascii=False, indent=4)
    except requests.RequestException as e:
        logger.error(f"è¯·æ±‚å¤±è´¥: {e}") 


def convert_docs_to_prompt(docs):
    prompt = ""
    for doc in docs:
        available_sizes = ", ".join([variation["sizeName"] for variation in ast.literal_eval(doc.metadata["variations"])])
        prompt += f"äº§å“åç§°: \"{doc.metadata['productName']}\", é¢œè‰²: {ast.literal_eval(doc.metadata["variations"])[0]['colorName']}, ä»·æ ¼: {doc.metadata['price']}, å¯ç”¨å°ºç : {available_sizes}\n"
    return prompt


if __name__ == "__main__":
    with open(settings.PROCESSED_DATA_PATH, "r", encoding="utf-8") as f:
        data = json.load(f)
    from src.indexing.embedding import generate_documents
    docs = generate_documents()
    print(extract_details_from_doc(docs[0]))
