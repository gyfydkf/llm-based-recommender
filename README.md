# ğŸ›ï¸ LLM-Based E-Commerce Fashion Recommender

**AI-powered fashion recommendation system leveraging LLMs, embeddings, and retrieval techniques to deliver personalized shopping experiences.**



---

## ğŸš€ Project Overview

This project is a **Retrieval-Augmented Generation (RAG)** chatbot designed for **fashion e-commerce**. It provides **personalized recommendations, answers product queries**, and **enhances user engagement** using **state-of-the-art LLMs and vector-based retrieval**.

Built with **FastAPI, FAISS, ChromaDB, LangChain, Ollama, and Streamlit**, this system efficiently indexes a **30K-product fashion dataset** and serves real-time recommendations.

---

## âœ¨ Features

âœ… **AI-Powered Fashion Recommendations** â€“ Get **smart** and **personalized** product suggestions.\
âœ… **Hybrid Retrieval (FAISS + BM25 + ChromaDB)** â€“ Multi-modal search for **better results**.\
âœ… **LLM-Driven Q&A** â€“ Handles **customer queries** with **real-time responses**.\
âœ… **Cross-Encoder Reranking** â€“ Improves **retrieval accuracy**.\
âœ… **Self-Querying Retriever** â€“ Converts queries into **structured filters**.\
âœ… **Streamlit Chatbot UI** â€“ A modern, user-friendly **interface**.\
âœ… **FastAPI Backend** â€“ A **scalable API** serving the recommender.\
âœ… **Dockerized Deployment** â€“ Runs seamlessly **in containers**.

---

## ğŸ—ï¸ Tech Stack

| Category                | Tools Used                              |
| ----------------------- | --------------------------------------- |
| **Programming**         | `Python 3.12`                           |
| **LLM Models**          | `GPT-4o-mini`, `Llama 3.2:3B`, `Ollama` |
| **Vector Search**       | `FAISS`, `ChromaDB`                     |
| **Retrieval & Ranking** | `BM25`, `LangChain`                     |
| **Backend**             | `FastAPI`, `Pydantic`, `Loguru`         |
| **Frontend**            | `Streamlit`                             |
| **Deployment**          | `Docker`, `Docker Compose`              |
| **Data Handling**       | `Pandas`, `Numpy`, `Kaggle API`         |
| **GPU Acceleration**    | `CUDA`, `NVIDIA Docker`, `PyTorch`      |

---

## ğŸ”§ Setup & Installation

### 1ï¸âƒ£ Prerequisites

- Python **3.12+**
- Docker & Docker Compose
- Ollama installed on your machine

### 2ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/amine-akrout/llm-based-recommender.git
cd llm-based-recommender
```

### 3ï¸âƒ£ Set Up Environment

Copy the example `.env` file and configure necessary credentials:

```bash
cp .env.example .env
```

Modify the `.env` file to include your **Kaggle API key**, **OpenAI API key**, and **other configurations**.

### 4ï¸âƒ£ Run the Application

#### ğŸ³ **With Docker Compose** (Recommended)

##### CPU Version
```bash
docker-compose up --build
```
Or 
```bash
Make docker-start
```

##### ğŸš€ **GPU Version** (Recommended for Performance)
```bash
# Windows
run_gpu.bat

# Linux/macOS
./run_gpu.sh

# Or manually
docker-compose -f docker-compose.gpu.yml up --build
```

**GPUç‰ˆæœ¬æä¾›3-15å€çš„æ€§èƒ½æå‡ï¼** æŸ¥çœ‹ [GPUä½¿ç”¨æŒ‡å—](docs/GPU_GUIDE.md) äº†è§£è¯¦æƒ…ã€‚

#### ğŸ—ï¸ **Manual Setup (Local Environment) using Makefile**

```bash
Make install-python # Install Python
Make install # Install dependencies
Make indexing # Index the dataset
Make retriever # Create the retriever
Make app # Start the FastAPI app
Make ui # Start the Streamlit UI
```

---

## ğŸ“¡ API Endpoints

The FastAPI backend exposes multiple endpoints. After running the API, visit **Swagger Docs**:

ğŸ”— **Swagger UI**: [`http://localhost:8000/docs`](http://localhost:8000/docs)\
ğŸ”— **Redoc**: [`http://localhost:8000/redoc`](http://localhost:8000/redoc)

| Method | Endpoint      | Description                         |
| ------ | ------------- | ----------------------------------- |
| `POST` | `/recommend/` | Get fashion product recommendations |
| `GET`  | `/health`     | Check API health status             |

---

## ğŸ–¥ï¸ Streamlit Chatbot UI

ğŸ”— **Access the UI** at: [`http://localhost:8501`](http://localhost:8501)

The chatbot interface allows users to **ask for product recommendations**, filter results, and get **AI-powered responses**.

---

## ğŸ“Š Data & Indexing

The recommender is built using a **30K-product e-commerce dataset** indexed with **FAISS, BM25, and ChromaDB**.

### Indexing Pipeline:

1. **Download Dataset** â€“ Uses `Kaggle API`
2. **Preprocess Data** â€“ Cleans and structures the dataset
3. **Generate Embeddings** â€“ Vectorizes product descriptions
4. **Store in FAISS & BM25** â€“ Hybrid retrieval for fast search

---


## ğŸ”„ Recommendation Flow

The chatbot's recommendation process follows a structured **LangGraph workflow**:

![Recommendation Flow](assets/flow.png)

1. **Check Topic**: Determines if the query is relevant to fashion.
2. **Self-Query Retrieve**: Extracts relevant product information.
3. **Ranker**: If retrieval returns empty, BM25 & FAISS rank results.
4. **RAG Recommender**: Uses LLM to generate the final recommendation.



---
<!-- streamlit demo -->
## ğŸ“º Demo 

![Demo](assets/demo.png)


## ğŸ› ï¸ Project Structure

```
ğŸ“¦ llm-based-recommender
â”œâ”€â”€ ğŸ“‚ src
â”‚   â”œâ”€â”€ ğŸ“‚ api                 # FastAPI Backend
â”‚   â”œâ”€â”€ ğŸ“‚ indexing            # FAISS, BM25, Chroma Indexing
â”‚   â”œâ”€â”€ ğŸ“‚ retriever           # Query Processing
â”‚   â”œâ”€â”€ ğŸ“‚ recommender         # Core LLM-based Recommender
â”‚   â”œâ”€â”€ ğŸ“‚ ui                  # Streamlit Chatbot
â”‚   â”œâ”€â”€ config.py              # App Configuration
â”œâ”€â”€ ğŸ“„ docker-compose.yml      # Docker Services
â”œâ”€â”€ ğŸ“„ Dockerfile              # API Containerization
â”œâ”€â”€ ğŸ“„ pyproject.toml          # Project Dependencies
â”œâ”€â”€ ğŸ“„ requirements.txt        # Python Packages
â”œâ”€â”€ ğŸ“„ .env.example            # Environment Variables
```

---

## ğŸ¯ Future Improvements

ğŸ”¹ **Fine-tune LLM for better recommendations**\
ğŸ”¹ **Improve UI/UX with product images**\
ğŸ”¹ **Add multi-language support**\
ğŸ”¹ **Deploy to AWS/GCP**\
ğŸ”¹ **Multi-GPU support for enterprise deployment**\
ğŸ”¹ **Real-time GPU performance monitoring**

---

## ğŸ† Contributing

Contributions are welcome! If youâ€™d like to contribute:

1ï¸âƒ£ Fork the repo\
2ï¸âƒ£ Create a new branch\
3ï¸âƒ£ Commit your changes\
4ï¸âƒ£ Submit a pull request

For major changes, please open an issue first to discuss what youâ€™d like to change.

---

## â­ Star This Repo!

If you find this project useful, donâ€™t forget to **â­ star** the repository! ğŸš€âœ¨

---

### ğŸ“© Contact

ğŸ‘¤ **Amine**\
ğŸ’¼ [**LinkedIn**](https://linkedin.com/in/akroutamine)

---
