#!/usr/bin/env python3
"""
GPU setup and verification script for the recommendation system.
"""

import subprocess
import sys
import os
import json
from pathlib import Path

def check_nvidia_driver():
    """Check if NVIDIA driver is installed."""
    print("ğŸ” æ£€æŸ¥NVIDIAé©±åŠ¨...")
    
    try:
        result = subprocess.run(
            ["nvidia-smi"],
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            print("âœ… NVIDIAé©±åŠ¨å·²å®‰è£…")
            print("GPUä¿¡æ¯:")
            print(result.stdout)
            return True
        else:
            print("âŒ NVIDIAé©±åŠ¨æœªå®‰è£…æˆ–æœ‰é—®é¢˜")
            return False
            
    except FileNotFoundError:
        print("âŒ nvidia-smi å‘½ä»¤æœªæ‰¾åˆ°")
        return False
    except Exception as e:
        print(f"âŒ æ£€æŸ¥NVIDIAé©±åŠ¨æ—¶å‡ºé”™: {e}")
        return False

def check_docker_gpu():
    """Check if Docker has GPU support."""
    print("\nğŸ” æ£€æŸ¥Docker GPUæ”¯æŒ...")
    
    try:
        result = subprocess.run(
            ["docker", "run", "--rm", "--gpus", "all", "nvidia/cuda:12.1.0-base-ubuntu22.04", "nvidia-smi"],
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            print("âœ… Docker GPUæ”¯æŒæ­£å¸¸")
            print("å®¹å™¨å†…GPUä¿¡æ¯:")
            print(result.stdout)
            return True
        else:
            print("âŒ Docker GPUæ”¯æŒæœ‰é—®é¢˜")
            print("é”™è¯¯ä¿¡æ¯:", result.stderr)
            return False
            
    except Exception as e:
        print(f"âŒ æ£€æŸ¥Docker GPUæ”¯æŒæ—¶å‡ºé”™: {e}")
        return False

def check_gpu_memory():
    """Check available GPU memory."""
    print("\nğŸ” æ£€æŸ¥GPUå†…å­˜...")
    
    try:
        result = subprocess.run(
            ["nvidia-smi", "--query-gpu=memory.total,memory.free,memory.used", "--format=csv,noheader,nounits"],
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            lines = result.stdout.strip().split('\n')
            for i, line in enumerate(lines):
                total, free, used = map(int, line.split(', '))
                print(f"GPU {i}:")
                print(f"  æ€»å†…å­˜: {total} MB")
                print(f"  å·²ç”¨å†…å­˜: {used} MB")
                print(f"  å¯ç”¨å†…å­˜: {free} MB")
                print(f"  ä½¿ç”¨ç‡: {(used/total)*100:.1f}%")
                
                if free < 2000:  # Less than 2GB free
                    print("  âš ï¸  å¯ç”¨å†…å­˜è¾ƒå°‘ï¼Œå¯èƒ½å½±å“æ€§èƒ½")
                else:
                    print("  âœ… å†…å­˜å……è¶³")
        else:
            print("âŒ æ— æ³•è·å–GPUå†…å­˜ä¿¡æ¯")
            
    except Exception as e:
        print(f"âŒ æ£€æŸ¥GPUå†…å­˜æ—¶å‡ºé”™: {e}")

def install_nvidia_docker():
    """Install NVIDIA Docker support."""
    print("\nğŸ”§ å®‰è£…NVIDIA Dockeræ”¯æŒ...")
    
    try:
        # Check if nvidia-docker is already installed
        result = subprocess.run(
            ["docker", "run", "--rm", "--gpus", "all", "nvidia/cuda:12.1.0-base-ubuntu22.04", "nvidia-smi"],
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            print("âœ… NVIDIA Dockeræ”¯æŒå·²å®‰è£…")
            return True
            
        print("æ­£åœ¨å®‰è£…NVIDIA Dockeræ”¯æŒ...")
        
        # Install nvidia-docker2
        commands = [
            ["distribution=$(. /etc/os-release;echo $ID$VERSION_ID)"],
            ["curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -"],
            ["curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list"],
            ["sudo apt-get update"],
            ["sudo apt-get install -y nvidia-docker2"],
            ["sudo systemctl restart docker"]
        ]
        
        for cmd in commands:
            print(f"æ‰§è¡Œ: {' '.join(cmd)}")
            result = subprocess.run(
                cmd,
                shell=True,
                capture_output=True,
                text=True
            )
            
            if result.returncode != 0:
                print(f"âŒ å‘½ä»¤å¤±è´¥: {result.stderr}")
                return False
        
        print("âœ… NVIDIA Dockeræ”¯æŒå®‰è£…å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"âŒ å®‰è£…NVIDIA Dockeræ”¯æŒæ—¶å‡ºé”™: {e}")
        return False

def create_gpu_requirements():
    """Create GPU-optimized requirements file."""
    print("\nğŸ”§ åˆ›å»ºGPUä¼˜åŒ–ä¾èµ–æ–‡ä»¶...")
    
    gpu_requirements = """# GPU-optimized requirements
torch==2.1.0+cu121
torchvision==0.16.0+cu121
torchaudio==2.1.0+cu121
transformers[torch]==4.35.0
accelerate==0.24.0
sentence-transformers==2.2.2
faiss-gpu==1.7.4
chromadb==0.4.18
rank-bm25==0.2.2
fastapi==0.104.1
uvicorn==0.24.0
streamlit==1.28.1
requests==2.31.0
pandas==2.1.3
numpy==1.24.3
scikit-learn==1.3.2
"""
    
    try:
        with open("requirements.gpu.txt", "w") as f:
            f.write(gpu_requirements)
        print("âœ… GPUä¼˜åŒ–ä¾èµ–æ–‡ä»¶å·²åˆ›å»º: requirements.gpu.txt")
        return True
    except Exception as e:
        print(f"âŒ åˆ›å»ºGPUä¾èµ–æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return False

def run_gpu_test():
    """Run a simple GPU test."""
    print("\nğŸ§ª è¿è¡ŒGPUæµ‹è¯•...")
    
    test_script = """
import torch
import transformers

print("PyTorchç‰ˆæœ¬:", torch.__version__)
print("CUDAå¯ç”¨:", torch.cuda.is_available())
if torch.cuda.is_available():
    print("CUDAè®¾å¤‡æ•°é‡:", torch.cuda.device_count())
    print("å½“å‰CUDAè®¾å¤‡:", torch.cuda.current_device())
    print("è®¾å¤‡åç§°:", torch.cuda.get_device_name(0))
    print("GPUå†…å­˜:", torch.cuda.get_device_properties(0).total_memory / 1024**3, "GB")
    
    # Test GPU computation
    x = torch.randn(1000, 1000).cuda()
    y = torch.randn(1000, 1000).cuda()
    z = torch.mm(x, y)
    print("GPUè®¡ç®—æµ‹è¯•é€šè¿‡")
else:
    print("CUDAä¸å¯ç”¨")
"""
    
    try:
        result = subprocess.run(
            [sys.executable, "-c", test_script],
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0:
            print("âœ… GPUæµ‹è¯•é€šè¿‡")
            print(result.stdout)
        else:
            print("âŒ GPUæµ‹è¯•å¤±è´¥")
            print(result.stderr)
            
    except Exception as e:
        print(f"âŒ è¿è¡ŒGPUæµ‹è¯•æ—¶å‡ºé”™: {e}")

def create_gpu_docker_script():
    """Create a script to run the system with GPU support."""
    print("\nğŸ”§ åˆ›å»ºGPUè¿è¡Œè„šæœ¬...")
    
    script_content = """#!/bin/bash
# GPU-enabled Docker Compose script

echo "ğŸš€ å¯åŠ¨GPUæ”¯æŒçš„æ¨èç³»ç»Ÿ..."

# Check if GPU is available
if ! nvidia-smi &> /dev/null; then
    echo "âŒ NVIDIA GPUä¸å¯ç”¨"
    exit 1
fi

# Check if nvidia-docker is available
if ! docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi &> /dev/null; then
    echo "âŒ NVIDIA Dockeræ”¯æŒä¸å¯ç”¨"
    echo "è¯·è¿è¡Œ: python scripts/setup_gpu.py"
    exit 1
fi

# Stop existing containers
docker-compose down

# Build and run with GPU support
docker-compose -f docker-compose.gpu.yml up --build

echo "âœ… GPUç³»ç»Ÿå¯åŠ¨å®Œæˆ"
echo "è®¿é—®åœ°å€: http://localhost:8501"
"""
    
    try:
        with open("run_gpu.sh", "w") as f:
            f.write(script_content)
        
        # Make it executable
        subprocess.run(["chmod", "+x", "run_gpu.sh"])
        
        print("âœ… GPUè¿è¡Œè„šæœ¬å·²åˆ›å»º: run_gpu.sh")
        return True
    except Exception as e:
        print(f"âŒ åˆ›å»ºGPUè¿è¡Œè„šæœ¬æ—¶å‡ºé”™: {e}")
        return False

def main():
    """Main function."""
    print("ğŸ”§ GPUè®¾ç½®å’Œæ£€æŸ¥å·¥å…·")
    print("=" * 50)
    
    # Check system requirements
    driver_ok = check_nvidia_driver()
    docker_gpu_ok = check_docker_gpu()
    
    if not driver_ok:
        print("\nâŒ è¯·å…ˆå®‰è£…NVIDIAé©±åŠ¨")
        print("ä¸‹è½½åœ°å€: https://www.nvidia.com/Download/index.aspx")
        return
    
    if not docker_gpu_ok:
        print("\nğŸ”§ å®‰è£…NVIDIA Dockeræ”¯æŒ...")
        install_nvidia_docker()
    
    # Check GPU memory
    check_gpu_memory()
    
    # Create GPU-optimized files
    create_gpu_requirements()
    create_gpu_docker_script()
    
    # Run GPU test
    run_gpu_test()
    
    print("\n" + "=" * 50)
    print("ğŸ“‹ GPUè®¾ç½®å®Œæˆï¼")
    print("\nä½¿ç”¨æ–¹æ³•:")
    print("1. è¿è¡ŒGPUç‰ˆæœ¬: ./run_gpu.sh")
    print("2. æˆ–æ‰‹åŠ¨è¿è¡Œ: docker-compose -f docker-compose.gpu.yml up --build")
    print("\næ€§èƒ½æå‡:")
    print("- LLMæ¨ç†é€Ÿåº¦æå‡ 3-10å€")
    print("- åµŒå…¥å‘é‡è®¡ç®—æå‡ 5-20å€")
    print("- æ•´ä½“å“åº”æ—¶é—´å‡å°‘ 50-80%")

if __name__ == "__main__":
    main() 